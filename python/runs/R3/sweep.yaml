program: training.py 
command:
  - /Users/sigge/miniforge3/envs/tf-finance/bin
  - ${interpreter}
  - ${program}
  - "--conv_start --collector=C1 --period=1y --interval=1d --start=2020.11.05 --stop=2021.11.05"
  - ${args}
method: bayes
metric:
  name: val_loss
  goal: minimize
parameters:
  learning_rate:
    min: 0.0000001
    max: 0.0001
  epochs:
    distribution: constant
    value: 50
  batch_size:
    distribution: categorical
    values: [1, 2, 4, 8, 16, 32, 64, 128, 256]
  # Set the data length to be constant because otherwise for conv_kernel_size, we will have no
  # idea of what the maximum value should be
  # data_length:
  #   distribution: int_uniform
  #   min: 2
  #   max: 60
  data_length:
    distribution: constant
    value: 7
  optimizer:
    distribution: categorical
    values: ["adam", "sgd"]
  loss_function:
    distribution: categorical
    values: ["mean_absolute_error", "mean_squared_error", "mean_absolute_percentage_error", "mean_squared_logarithmic_error", "cosine_similarity", "huber", "log_cosh"]
  activation_function:
    distribution: categorical
    values: ["relu", "sigmoid", "softmax", "softplus", "softsign", "tanh", "selu", "elu", "exponential"]
  conv_layers:
    distribution: int_uniform
    min: 1
    max: 10
  conv_filters:
    distribution: int_uniform
    min: 1
    max: 100
  # Make sure to change data_length when changing the max value of conv_kernel_size
  conv_kernel_size:
    distribution: int_uniform
    min: 1
    max: 7
  conv_padding:
    distribution: constant
    value: "same"
  dense_halve_each_time:
    distribution: categorical
    values: ["True", "False"]
  dense_layers:
    distribution: int_uniform
    min: 0
    max: 10
  dense_layer_nodes:
    distribution: categorical
    values: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]